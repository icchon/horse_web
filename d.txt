# 配布データと応募用ファイル作成方法の説明

本コンペティションで配布されるデータと応募用ファイルの作成方法や投稿する際の注意点について説明する.

1. [配布データ](#配布データ)
1. [応募用ファイルの作成方法](#応募用ファイルの作成方法)
1. [投稿時の注意点](#投稿時の注意点)

## 配布データ

配布されるデータは以下の通り.

- [Readme](#readme)
- [学習用データ](#学習用データ)
- [動作確認用のプログラム](#動作確認用のプログラム)
- [応募用サンプルファイル](#応募用サンプルファイル)

### Readme

本ファイル(`readme.md`)で, 配布用データの説明と応募用ファイルの作成方法を説明したドキュメント. マークダウン形式で, プレビューモードで見ることを推奨する.

### 学習用データ

ファイルは`train.zip`であり, 解凍すると以下のようなディレクトリ構造となるデータが生成される.

```bash
train
├── 00000.jpg
├── 00000.json
└── ...
```

`jpg`は画像データで同名の`json`は対応するアノテーションデータである. 画像データはある一行のくずし字で書かれた文が映ったものである. アノテーションデータは以下のようなフォーマットのjsonファイル(エンコーディングは`utf-8`)である.

```json
{
    "book_id": book_id,
    "page_id": page_id,
    "text": text,
    "labels": [
        {
            "label": label,
            "bbox": [
                left,
                top,
                right,
                bottom
            ]
        },
        ... 
    ]
}
```

`book_id`は書籍IDで, `page_id`はその書籍のページIDに対応している. `text`はくずし字を上から読んだ結果で, `labels`はそれぞれのくずし字の文字情報(`label`)と矩形情報(`bbox`)のリストである. 矩形情報は画像の左上を原点として左上の座標と右下の座標によって表現される(`left`: 左, `top`: 上, `right`: 右, `bottom`: 下).

### 動作確認用のプログラム

動作確認用プログラム一式は`run_test.zip`であり, 解凍すると以下のようなディレクトリ構造のデータが生成される.

```bash
run_test
├── src                    Pythonのプログラムを置くディレクトリ
│   ├── evaluator.py
│   ├── generator.py
│   ├── preprocessor.py
│   ├── runner.py
│   └── validator.py
├── submit                 投稿用のプログラムを置くディレクトリ
│   ├── model
│   │   └── init.txt
│   └── src
│       └── predictor.py
├── docker-compose.yml     分析環境を構築するためのdocker-composeファイル
├── Dockerfile             分析環境元のDockerファイル
├── evaluate.py            精度評価を行うためのプログラム
├── make_val.py            検証用のデータを作成するためのプログラム
├── make_submit.sh         投稿用のファイルを作成するためのプログラム
└── run.py                 実装した推論プログラムを実行するプログラム
```

使い方の詳細は[応募用ファイルの作成方法](#応募用ファイルの作成方法)を参照されたい.

### 応募用サンプルファイル

応募用サンプルファイルは`sample_submit.zip`として与えられる. 解凍すると以下のようなディレクトリ構造のデータが生成される.

```bash
sample_submit
├── model             学習済モデルを置くディレクトリ
│   └── init.txt
└── src
    └── predictor.py  最初のプログラムが呼び出すファイル
```

実際に作成する際に参照されたい.

## 応募用ファイルの作成方法

応募用ファイルは学習済みモデルを含めた, 推論を実行するためのソースコード一式をzipファイルでまとめたものとする.

### ディレクトリ構造

以下のようなディレクトリ構造となっていることを想定している.

```bash
.
├── model              必須: 学習済モデルを置くディレクトリ
│   └── ...
├── src                必須: Pythonのプログラムを置くディレクトリ
│   ├── predictor.py   必須: 最初のプログラムが呼び出すファイル
│   └── ...            その他のファイル (ディレクトリ作成可能)
└── requirements.txt   任意: 追加で必要なライブラリ一覧
```

- 学習済みモデルの格納場所は"model"ディレクトリを想定している.
  - 学習済みモデルを使用しない場合でも空のディレクトリを作成する必要がある.
  - 名前は必ず"model"とすること.
- Pythonのプログラムの格納場所は"src"ディレクトリを想定している.
  - 学習済みモデル等を読み込んで推論するためのメインのソースコードは"predictor.py"を想定している.
    - ファイル名は必ず"predictor.py"とすること.
  - その他推論を実行するために必要なファイルがあれば作成可能である.
  - ディレクトリ名は必ず"src"とすること.
- 実行するために追加で必要なライブラリがあれば, その一覧を"requirements.txt"に記載することで, 評価システム上でも実行可能となる.
  - インストール可能で実行可能かどうか予めローカル環境で試しておくこと.

### 環境構築

評価システムと同じ環境を用意する. Dockerイメージが[こちら(タグ名はbase_env)](https://hub.docker.com/r/signate/runtime-gpu)で公開されているので, pullしてコンテナを作成して環境構築を行うことを推奨する(GPUが搭載されている環境で構築することが望ましい). Dockerから環境構築する場合, Docker Engineなど, Dockerを使用するために必要なものがない場合はまずはそれらを導入しておく. [Docker Desktop](https://docs.docker.com/get-docker/)を導入すると必要なものがすべてそろうので, 自身の環境に合わせてインストーラをダウンロードして導入しておくことが望ましい. 現状, Linux, Mac, Windowsに対応している. そして, `/path/to/run_test`に同封してある`docker-compose.yml`で定義されたコンテナを, 以下のコマンドを実行することで立ち上げる.

```bash
$ cd /path/to/run_test
$ docker compose up -d
...
```

`docker-compose.yml`は好きに編集するなりして, 自身が使いやすいように改造してもよい. GPUが使えてCUDAを有効化したい場合は以下のように編集することでコンテナ内で使用することができる.

```yaml
version: "3"
services:
  dev1:
    image: signate/runtime-gpu:base_env
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    container_name: analysis_kuzushiji
    ports:
      - "8080:8080"
    volumes:
      - .:/workspace
    tty: true
```

インストールされている主なライブラリは以下の通り.

```bash
jupyterlab==3.6.3
opencv-python==4.8.0.74
Pillow==10.0.0
scikit-image==0.21.0
torch==2.0.1
torchvision==0.15.2
tensorflow-gpu==2.11.0
```

無事にコンテナが走ったら, 必要に応じてデータをコンテナへコピーする.

```bash
$ docker cp /path/to/some/file/or/dir {コンテナ名}: {コンテナ側パス}
... 
```

そして, 以下のコマンドでコンテナの中に入り, 分析や開発を行う.

```bash
$ docker exec -it {コンテナ名} bash
...
# コンテナに入った後
$ cd /workspace
```

`コンテナ名`には`docker-compose.yml`の`services`->`dev1`->`container_name`に記載の値を記述する. デフォルトでは`/path/to/run_test`をコンテナ側の`/workspace`へバインドマウントした状態(`/path/to/run_test`でファイルの編集などをしたらコンテナ側にも反映される. 逆もしかり.)となっている. 追加でPythonライブラリをインストールしたい場合は例えば`requirements.txt`によりコンテナの中でインストール可能.

```bash
# コンテナに入った後
$ cd /workspace
# requirements.txtを作成
$ pip install -r requirements.txt
...
```

CUDA環境を構築した場合, 実際にCUDAがコンテナ内で有効になっているかどうかは以下のコマンドで確認できる.

```bash
# コンテナに入った後
$ python -c "import torch; print(torch.cuda.is_available())"
True
$ python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
...{GPUデバイスのリスト}...
```

#### 補足

以下のコマンドで`jupyter lab`を立ち上げることができる.

```bash
# コンテナに入った後
$ cd /workspace
$ jupyter lab --port={ポート番号} --ip=0.0.0.0 --allow-root
...
copy and paste one of these URLs:
        ...
     or ...

```

`ポート番号`には`docker-compose.yml`で定義したコンテナ側のポート番号(`ports`の`:`の右側の値)を指定する. 表示されるURLをブラウザに張り付ければjupyterの環境で作業が可能となる. Desktopから直接入ってもよい(最初にtokenを聞かれるので, URLの`token=`に続く文字列を入力する).

### predictor.pyの実装方法

以下のクラスとメソッドを実装すること.

#### Predictor

推論実行のためのクラス. 以下のメソッドを実装すること.

##### get_model

モデルを取得するメソッド. 以下の条件を満たす必要がある.

- クラスメソッドであること.
- 引数model_path(str型)を指定すること.
  - 学習済みモデルが格納されているディレクトリのパスが渡される.
- 学習済みモデルの読み込みに成功した場合はTrueを返す.
  - モデル自体は任意の名前(例えば"model")で保存しておく.

##### predict

推論を実行するメソッド. 以下の条件を満たす必要がある.

- クラスメソッドであること.
- 引数v(str型)を指定すること.
  - 推論対象となる画像のパス名がstr型で渡される.
  - `get_model`メソッドで読み込んだ学習済みモデルを用いて対応する画像に対する予測を行う想定である.
- 渡された画像ファイルに映る文字を`str`型として返す.
  - 文章は縦書きで, 一行の文の想定である.
  - 映っている文字を上から順に記述する.
  - フリガナ, 挿入文字や朱傍書(赤字による修正)が一緒に見えるケースがあるが, それらは認識対象外とする.
  - 割注(一行の中に複数行の文字が書かれている場合)は右から順に読んで一行につなげる.

以下は実装例.

```Python
from PIL import Image


class Predictor(object):
    @classmethod
    def get_model(cls, model_path):
        """Get model method

        Args:
            model_path (str): Path to the trained model directory.

        Returns:
            bool: The return value. True for success.
        """
        cls.model = load_model(model_path)

        return True


    @classmethod
    def predict(cls, v):
        """Predict method

        Args:
            v: Path of the sample you want to make inference from (str)

        Returns:
            pred: Inference for the given input.

        """
        img = Image.open(v)
        preprocessed = preprocess_image(img)
        output = cls.model(preprocessed)
        pred = postprocess_output(output)

        return pred


def load_model(model_path):
    ...
    return model


def preprocess_image(img):
    ...
    return preprocessed


def postprocess_output(output):
    """
    returns: str
    """
    ...
    return pred
```

[`run_test/submit/src/predictor.py`](./run_test/submit/src/predictor.py)や応募用サンプルファイル`sample_submit.zip`も参照すること.

### 推論テスト

推論を行うプログラムが実装できたら, 正常に動作するか確認する.

以下, コンテナ内での作業とする.

#### 検証用データの作成

画像データとアノテーションデータから検証用のデータを作成する. 画像データとアノテーションデータのセットが格納されたディレクトリ(あらかじめ学習用データなどから検証に使うデータを抜き出して作成しておくとよい)を指定して作成できる.

```bash
$ python make_val.py
...
```

8行目の`image_dir`に好きなディレクトリ名を指定する. 実行後, 作業ディレクトリ直下に入力用のデータ(`input.json`)と解答データ(`ans.json`)が作成される.

#### 推論の実行

配布データを用いてモデル学習などを行い, [動作確認用のプログラム](#動作確認用のプログラム)を用いて検証用のデータを作成し, 推論を実行する.

```bash
$ python run.py  --exec-dir /path/to/submit/src --input-data-path /path/to/input.json --val-data-dir /path/to/val --result-dir /path/to/result/dir --result-name result_name
...
```

- `--exec-path`には実装した予測プログラム("predictor.py")が存在するパス名を指定する.
- `--input-data-path`には作成した検証用データに関する入力用のデータ(`input.json`)の格納先を指定する.
- `--val-data-dir`には作成した検証用データの格納先のディレクトリを指定する.
- `--result-dir`には推論結果の格納先のディレクトリを指定する. デフォルトは`./results`.
- `--result-name`には推論結果ファイルの名前を指定する. デフォルトは`predictions.json`.

実行に成功すると, 推論時間などが出力され, `{result_dir}/{result_name}`として推論結果ファイルが保存される.

#### 精度評価の実行

[推論の実行](#推論の実行)で得られた結果を精度評価する.

```bash
$ python evaluate.py  --result-path /path/to/result --ans-path /path/to/ans.json --input-path /path/to/input.json
...
```

- `--result-path`には[推論の実行](#推論の実行)で得られた結果ファイルのパスを指定する. デフォルトは`./results/predictions.json`
- `--ans-path`には作成した解答ファイルのパスを指定する. デフォルトは`./ans.json`.
- `--input-path`には作成した入力データファイルのパスを指定する. デフォルトは`./input.json`

実行に成功すると最終精度評価が出力される.

投稿する前にエラーが出ずに実行が成功することを確認すること.

### 応募用ファイルの作成

上記の[ディレクトリ構造](#ディレクトリ構造)となっていることを確認して, zipファイルとして圧縮する. 以下のコマンドで応募用ファイルを作成可能.

```bash
$ bash make_submit.sh
...
```

実行後, 作業ディレクトリにおいて`submit.zip`が作成される.

## 投稿時の注意点

投稿する前に自身のローカル環境などで実行テストを行い, エラーなく実行できるか確認すること. 投稿時にエラーが出た場合, 以下のことについて確認してみる.

- 提出するプログラム内でインターネット接続を行うような処理を含めていないか. 評価システム上でインターネット接続はできない.
- 追加でインストールしたライブラリを`requirements.txt`に含めているか.
- `predict`メソッドを呼んだときに必ず`None`ではない何らかの結果を返しているか(今回の場合は`str`型).
- 実行時間がかかりすぎていないか. 少数のサンプルで正常に動いても, 時間がかかりすぎるとランタイムエラーとなることがある. 使用メモリなども見直すこと.

## 特記事項

本コンペティションで提供されている[学習用データ](#学習用データ)は以下の著作物を加工して作成したものである.

- 提供元: [人文学オープンデータ共同利用センター](http://codh.rois.ac.jp/)
- 『日本古典籍くずし字データセット』（国文研ほか所蔵／CODH加工） doi:10.20676/00000340

ライセンスは以下

- [クリエイティブ・コモンズ 表示 - 継承 4.0 国際 ライセンス（CC BY-SA）](https://creativecommons.org/licenses/by-sa/4.0/)
